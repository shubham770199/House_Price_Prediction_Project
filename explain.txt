üîπ 1. Load Libraries and Dataset
python
Copy
Edit
import pandas as pd
Pandas is imported to handle data loading and manipulation.

python
Copy
Edit
df = pd.read_csv("data/Housing.csv")
Loads the CSV file Housing.csv from the data folder into a DataFrame df.

python
Copy
Edit
print("First 5 rows of the dataset:")
print(df.head())
Prints the first 5 rows of the dataset to understand its structure and content.

python
Copy
Edit
print("\nDataset Info:")
print(df.info())
Displays column names, non-null counts, and data types.

python
Copy
Edit
print("\nStatistical Summary:")
print(df.describe())
Displays statistics like mean, std, min, max for numeric columns.

üîπ 2. Preprocessing the Data
python
Copy
Edit
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
import numpy as np
Imports tools for splitting the dataset, encoding, and using NumPy.

python
Copy
Edit
binary_columns = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']
for col in binary_columns:
    df[col] = df[col].map({'yes': 1, 'no': 0})
Converts 'yes' and 'no' columns into binary values (1 and 0) for machine learning.

python
Copy
Edit
df = pd.get_dummies(df, columns=['furnishingstatus'], drop_first=True)
Converts the categorical column furnishingstatus into dummy/one-hot variables, dropping the first category to avoid multicollinearity.

python
Copy
Edit
X = df.drop('price', axis=1)
y = df['price']
Splits the dataset:

X: all features (independent variables)

y: the target (price)

python
Copy
Edit
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
Splits the data into training (80%) and testing (20%) sets.

python
Copy
Edit
print("\nData Preprocessing Completed!")
print(f"Training samples: {X_train.shape[0]}")
print(f"Testing samples: {X_test.shape[0]}")
Displays number of training and testing samples.

üîπ 3. Model Training & Evaluation
python
Copy
Edit
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
Imports 3 ML models:

LinearRegression: a simple linear model.

RandomForestRegressor: an ensemble tree-based model.

XGBRegressor: a powerful gradient boosting model.

Also imports evaluation metrics:

MAE, MSE, R¬≤ Score.

‚úÖ Define evaluation function
python
Copy
Edit
def evaluate_model(name, model, X_train, y_train, X_test, y_test):
    model.fit(X_train, y_train)
    preds = model.predict(X_test)

    print(f"\nüìä Evaluation for: {name}")
    print(f"MAE: {mean_absolute_error(y_test, preds):,.2f}")
    print(f"MSE: {mean_squared_error(y_test, preds):,.2f}")
    print(f"R¬≤ Score: {r2_score(y_test, preds):.4f}")
Fits the model, makes predictions, and prints evaluation metrics:

MAE: average absolute error

MSE: average squared error

R¬≤ Score: how well model explains the data (1 is best)

üîç Evaluate 3 Models
python
Copy
Edit
evaluate_model("Linear Regression", LinearRegression(), X_train, y_train, X_test, y_test)
evaluate_model("Random Forest", RandomForestRegressor(n_estimators=100, random_state=42), X_train, y_train, X_test, y_test)
evaluate_model("XGBoost Regressor", XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42), X_train, y_train, X_test, y_test)
Trains and evaluates:

Linear Regression

Random Forest

XGBoost

You‚Äôll see the model performance printed after this step.

üîπ 4. Save the Best Model
python
Copy
Edit
import joblib
import os
joblib: used to save the model.

os: used to check/create directories.

python
Copy
Edit
best_model = RandomForestRegressor(n_estimators=100, random_state=42)
best_model.fit(X_train, y_train)
Based on previous evaluations, selects Random Forest as the best model and trains it on the full training data.

python
Copy
Edit
if not os.path.exists('models'):
    os.makedirs('models')
Creates a models directory if it doesn't already exist.

python
Copy
Edit
joblib.dump(best_model, "models/final_model.pkl")
Saves the trained model to a .pkl file for later use.

python
Copy
Edit
print("\n‚úÖ Best model saved as 'final_model.pkl' in /models folder.")
Confirmation that the model has been saved successfully.